{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "17.10.1 Oversampling\n",
    "\n",
    "Jill congratulates you on the great work you've done so far. Well done! Before setting you free to tackle your machine learning assignment, however, she would like you to become familiar with a family of resampling techniques designed to deal with class imbalance.\n",
    "\n",
    "Class imbalance is a common problem in classification. It occurs when one class is much larger than the other class. For example, if you work for a credit card company and want to detect fraudulent transactions, you will deal with many more non-fraudulent transactions than fraudulent ones. In this case, the non-fraudulent class is much larger than the fraudulent class.\n",
    "\n",
    "Under Jill's tutelage, you will learn about three techniques to address class imbalance: oversampling, undersampling, and a combination approach of oversampling and undersampling. But for now, you'll start with oversampling."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Class imbalance refers to a situation in which the existing classes in a dataset aren't equally represented. Earlier we discussed a fraud detection scenario in which a large number of credit card transactions are legitimate, and only a small number are fraudulent. \n",
    "\n",
    "For example, let's say that out of 100,000 transactions, 50 are fraudulent and the rest are legitimate. The pronounced imbalance between the two classes (fraudulent and non-fraudulent) can cause machine learning models to be biased toward the majority class. \n",
    "\n",
    "In such a case, the model will be much better at predicting non-fraudulent transactions than fraudulent ones. This is a problem if the goal is to detect fraudulent transactions!\n",
    "\n",
    "In such a case, even a model that blindly classifies every transaction as non-fraudulent will achieve a very high degree of accuracy. As we saw previously, one strategy to deal with class imbalance is to use appropriate metrics to evaluate a model's performance, such as precision and recall.\n",
    "\n",
    "Another strategy is to use oversampling. The idea is simple and intuitive: If one class has too few instances in the training set, we choose more instances from that class for training until it's larger.\n",
    "\n",
    "We'll discuss two oversampling techniques: random oversampling and synthetic minority oversampling technique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random Oversampling\n",
    "\n",
    "In random oversampling, instances of the minority class are randomly selected and added to the training set until the majority and minority classes are balanced. The Python implementation is simple.\n",
    "\n",
    "To get started, download the necessary files: oversampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Open the downloaded Jupyter Notebook. After importing dependencies, an unbalanced dataset with two classes is artificially created and plotted, as shown in the following code blocks and resulting chart.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from collections import Counter\n",
    "\n",
    "X, y = make_blobs(n_samples=[600, 60], random_state=1, cluster_std=5)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The visualization confirms the imbalanceâ€”the purple class visibly outnumbers the yellow class.\n",
    "\n",
    "Next, the dataset is split into training and testing sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "Counter(y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Python's Counter module confirms the imbalance in the training set. There are 451 samples from the purple class and 44 samples from the yellow class.\n",
    "\n",
    "Counter({0: 451, 1: 44})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next, we randomly oversample the minority class with the imblearn library.\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Let's break down what's happening here:\n",
    "\n",
    "- An instance of RandomOverSampler is instantiated as ros.\n",
    "\n",
    "- The training data (X_train and y_train) is resampled using the fit_resample() method.\n",
    "\n",
    "- The results are called X_resampled and y_resampled.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Counting the classes of the resampled target verifies that the minority class has been enlarged.\n",
    "\n",
    "Counter(y_resampled)\n",
    "\n",
    "Counter({0: 17532, 1: 4968})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With a resampled dataset, we can now carry out the familiar pattern of training a model, making predictions, and evaluating the model's performance. For this example, we'll use a LogisticRegression model. The following code instantiates and trains the model.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model creates predictions. We then generate a confusion_matrix with the results.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To assess the accuracy score of the model, we'll use the balanced_accuracy_score module.\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The accuracy score is high at around 90%, but this number can be misleading, especially in an unbalanced dataset. Let's examine the classification report to assess the results further. We'll use the classification_report_imbalanced to do so.\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n",
    "\n",
    "While precision (\"pre\" column) and recall (\"rec\" column) are high for the majority class, precision is low for the minority class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Synthetic Minority Oversampling Technique\n",
    "\n",
    "The synthetic minority oversampling technique (SMOTE) is another oversampling approach to deal with unbalanced datasets. In SMOTE, like random oversampling, the size of the minority is increased. \n",
    "\n",
    "The key difference between the two lies in how the minority class is increased in size. As we have seen, in random oversampling, instances from the minority class are randomly selected and added to the minority class. In SMOTE, by contrast, new instances are interpolated. \n",
    "\n",
    "That is, for an instance from the minority class, a number of its closest neighbors is chosen. Based on the values of these neighbors, new values are created.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Which of the following best describes the difference between random oversampling and SMOTE?\n",
    "\n",
    "Random oversampling draws from existing observations, whereas SMOTE generates synthetic observations."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's look at SMOTE in action. Note that the following code is contained in the same Jupyter Notebook as the random oversampling example, and that we are using the same training data (X_train and y_train). We use the SMOTE module from the imblearn library to oversample the minority class.\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE(random_state=1,\n",
    "sampling_strategy='auto').fit_resample(\n",
    "   X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following actions are taking place:\n",
    "\n",
    "1. The sampling_strategy argument specifies how the dataset is resampled. By default, it increases the minority class size to equal the majority class's size.\n",
    "\n",
    "2. Again, the fit_resample() method is used on the training data to train the SMOTE model and to oversample in a single step."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Counting the number of instances by class verifies that they are now equal in size.\n",
    "\n",
    "Counter(y_resampled)\n",
    "\n",
    "Counter({0:451, 1:451})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We'll again train a LogisticRegression model, predict, then assess the accuracy and generate a confusion_matrix, as shown in the following code blocks.\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The metrics of the minority class (precision, recall, and F1 score) are slightly improved over those of random oversampling.\n",
    "\n",
    "It's important to note that although SMOTE reduces the risk of oversampling, it does not always outperform random oversampling. Another deficiency of SMOTE is its vulnerability to outliers.\n",
    "\n",
    "We said earlier that a minority class instance is selected, and new values are generated based on its distance from its neighbors. If the neighbors are extreme outliers, the new values will reflect this. Finally, keep in mind that sampling techniques cannot overcome the deficiencies of the original dataset!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "17.10.2 Undersampling\n",
    "\n",
    "You've learned that in oversampling, the smaller class is resampled to make it larger. Undersampling, in contrast, takes the opposite tack. Jill recommends that you look at random undersampling as well as a synthetic approach."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Undersampling is another technique to address class imbalance. Undersampling takes the opposite approach of oversampling. Instead of increasing the number of the minority class, the size of the majority class is decreased."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Keep in mind that both oversampling and undersampling involve tradeoffs. Oversampling addresses class imbalance by duplicating or mimicking existing data. In contrast, undersampling only uses actual data. On the other hand, undersampling involves loss of data from the majority class. Furthermore, undersampling is practical only when there is enough data in the training set. There must be enough usable data in the undersampled majority class for a model to be useful.\n",
    "\n",
    "We'll discuss two approaches to undersampling: random and cluster centroid. Both are similar to the oversampling methods we've seen. Download the files and let's look at the examples together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random Undersampling\n",
    "\n",
    "In random undersampling, randomly selected instances from the majority class are removed until the size of the majority class is reduced, typically to that of the minority class. The dataset used in this example contains information on credit card default.\n",
    "\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from collections import Counter\n",
    "\n",
    "data = Path('../Resources/cc_default.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following legend explains the values used in the columns:\n",
    "\n",
    "1. ln_balance_limit: maximum balance limit on a card\n",
    "2. sex: 1 = female, 0 = sex\n",
    "3. education: 1 = graduate school, 2 = university, 3 = high school, 4 = others\n",
    "4. marriage: 1 = married, 0 = single\n",
    "5. age: age of credit card holder\n",
    "6. default_next_month: 1 = yes, 0 = no"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The target variable, default_next_month, describes whether a credit card holder defaults during the next month. The features are all columns in the dataset, except ID and default_next_month, with the former not a useful predictor of default status and the latter the target. We can drop these columns as we have done before, or we can use a list comprehension, as shown below.\n",
    "\n",
    "x_cols = [i for i in df.columns if i not in ('ID', 'default_next_month')]\n",
    "X = df[x_cols]\n",
    "y = df['default_next_month']\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The rest of the code used for undersampling is very similar to that used for oversampling. We first split the dataset into training and testing sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next, we use imblearn's RandomUnderSampler module to train the RandomUnderSampler instance, then undersample the majority class. Counting the class verifies that both classes are the same size.\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "ros = RandomUnderSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A LogisticRegression model will be used again on the dataset. We first train it.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Then, we make predictions and generate a confusion_matrix.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "array([[3732, 2100],\n",
    "[ 740, 928]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We calculate the balanced_accuracy_score, which is 0.598.\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "Generally, the results are unimpressive, especially for predicting defaults. Let's see whether another undersampling technique will improve the metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cluster Centroid Undersampling\n",
    "\n",
    "Cluster centroid undersampling is akin to SMOTE. The algorithm identifies clusters of the majority class, then generates synthetic data points, called centroids, that are representative of the clusters. The majority class is then undersampled down to the size of the minority class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To implement this technique in Python, we'll use imblearn's ClusterCentroids module. The process is much the same as before:\n",
    "\n",
    "1. Fit and resample the training data.\n",
    "2. Train a logistic regression model.\n",
    "3. Create predictions.\n",
    "4. Assess the results."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, instantiate the resampling module and use it to resample the data.\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Then instantiate and train a logistic regression model.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next, generate the metrics.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "These results are worse than those from random undersampling! This underscores an important point: While resampling can attempt to address imbalance, it does not guarantee better results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SKILL DRILL\n",
    "\n",
    "Perform oversampling on this dataset and compare results. Which resampling technique yields better results?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "17.10.3 Combination Sampling With SMOTEENN\n",
    "\n",
    "You discuss the results of oversampling and undersampling with Jill. When you point out to her that the improvements seem to be modest, she explains that incremental improvements are usually more realistic than drastic ones. Jill also tells you that such small improvements, in tandem with other tweaks, can add up to make a significant difference. For now, however, she suggests learning about SMOTEENN, an approach to resampling that combines aspects of both oversampling and undersampling."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As previously discussed, a downside of oversampling with SMOTE is its reliance on the immediate neighbors of a data point. Because the algorithm doesn't see the overall distribution of data, the new data points it creates can be heavily influenced by outliers. This can lead to noisy data. With downsampling, the downsides are that it involves loss of data and is not an option when the dataset is small. One way to deal with these challenges is to use a sampling strategy that is a combination of oversampling and undersampling."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTEENN combines the SMOTE and Edited Nearest Neighbors (ENN) algorithms. SMOTEENN is a two-step process:\n",
    "\n",
    "1. Oversample the minority class with SMOTE.\n",
    "\n",
    "2. Clean the resulting data with an undersampling strategy. If the two nearest neighbors of a data point belong to two different classes, that data point is dropped."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The series of images below help illustrate the SMOTEENN technique. The first image represents a synthetically generated dataset (using the make_blobs module) and shows two classes: purple as the majority class and yellow as the minority class.\n",
    "\n",
    "In the following image, the minority class is oversampled with SMOTE.\n",
    "\n",
    "Note that the two classes significantly overlap, as the box indicates below. This overlap makes classification difficult.\n",
    "\n",
    "In the next image, SMOTEENN is applied, instead of SMOTE. As with SMOTE, the minority class is oversampled; however, an undersampling step is added, removing some of each class's outliers from the dataset. The result is that the two classes are separated more cleanly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's apply SMOTEENN to the credit card default dataset and compare its results.\n",
    "\n",
    "combination_sampling.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The code is much the same as before. The only difference is in using the SMOTEENN module.\n",
    "\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from collections import Counter\n",
    "\n",
    "data = Path('../Resources/cc_default.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Again, the ID and default_next_month columns are filtered to create the features dataset. The default_next_month column is defined as the target dataset.\n",
    "\n",
    "x_cols = [i for i in df.columns if i not in ('ID', 'default_next_month')]\n",
    "X = df[x_cols]\n",
    "y = df['default_next_month']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The dataset is split into training and testing sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next, we import the SMOTEENN module and create an instance of SMOTEENN, which resamples the dataset.\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Again, we use a LogisticRegression model to generate predictions.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As before, the evaluation metrics are generated. First, the confusion_matrix is generated.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next, the balanced_accuracy_score is generated.\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finally, we print the classification report.\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sResampling with SMOTEENN did not work miracles, but some of the metrics show an improvement over undersampling.\n",
    "\n",
    "Which of the following best describes the difference between SMOTE and SMOTEENN?\n",
    "\n",
    "SMOTE does not involve undersampling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
